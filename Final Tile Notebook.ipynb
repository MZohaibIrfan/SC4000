{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":58266,"databundleVersionId":6641124,"sourceType":"competition"}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ðŸŽ¯ Tile:XLA Runtime Prediction - Ensemble Approach\n\n## Overview\nThis notebook predicts the runtime of XLA compiler configurations for \"tile\" workloads using an ensemble of simple Multi-Layer Perceptron (MLP) models.\n\n### Competition Context\n- **Task**: Predict which configurations run fastest for each computational graph\n- **Dataset Portion**: This notebook handles `tile:xla` predictions only\n- **Approach**: Train lightweight MLPs on per-configuration features + graph-level statistics\n\n### Key Design Decisions\n1. **No GNN**: Unlike layout data, tile data has simple per-config features â†’ MLP is sufficient\n2. **Log-space targets**: Training on `log(runtime)` improves stability for skewed distributions\n3. **Ensemble**: 3 models with different seeds for robustness\n4. **Graph summaries**: 8 cheap statistical features capture graph complexity\n\n---","metadata":{}},{"cell_type":"markdown","source":"## ðŸ“¦ Section 1: Environment Setup\n\n### What we're doing:\n- Import necessary libraries\n- Set global configuration toggles\n- Initialize device and random seeds","metadata":{}},{"cell_type":"code","source":"# ===========================\n# 1.1 IMPORTS\n# ===========================\n\nimport os, time, random, warnings\nfrom pathlib import Path\nfrom typing import Dict, List, Optional\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm.auto import tqdm\n\nimport torch\nfrom torch import nn\nfrom torch import amp  # Modern AMP API (avoids deprecation warnings)\n\n# Suppress non-critical warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T16:21:57.741637Z","iopub.execute_input":"2025-11-04T16:21:57.741953Z","iopub.status.idle":"2025-11-04T16:22:04.049557Z","shell.execute_reply.started":"2025-11-04T16:21:57.741925Z","shell.execute_reply":"2025-11-04T16:22:04.048789Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# ===========================\n# 1.2 CONFIGURATION TOGGLES\n# ===========================\n\n# Target transformation\nUSE_LOG_TARGET = True  # Train on log(runtime_normalized) for better numerical stability\n\n# Feature engineering\nUSE_GRAPH_SUMMARY = True  # Add 8 graph-level features (node count, edge count, etc.)\n\n# Post-processing\nNORMALIZE_WITHIN_FILE = \"meanstd\"  # Options: 'off', 'mean', 'meanstd'\n                                     # Calibrate predictions per-file before ranking\n\n# Loss function\nUSE_RANKING_LOSS = False  # False = MSE loss (simpler); True = pairwise ranking loss\n\n# Training parameters\nENSEMBLE_SEEDS = [42, 43, 44]  # Train 3 models with different random seeds\nEPOCHS = 5\nBASE_LR = 1e-3\nWEIGHT_DECAY = 1e-5\nBATCH_SIZE = 131072  # Adjust based on GPU memory (131K configs per batch)\n\nprint(\"Configuration loaded:\")\nprint(f\"  â€¢ Ensemble size: {len(ENSEMBLE_SEEDS)} models\")\nprint(f\"  â€¢ Training epochs: {EPOCHS}\")\nprint(f\"  â€¢ Batch size: {BATCH_SIZE:,} samples\")\nprint(f\"  â€¢ Target: {'log(runtime)' if USE_LOG_TARGET else 'runtime'}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T16:22:04.051257Z","iopub.execute_input":"2025-11-04T16:22:04.051640Z","iopub.status.idle":"2025-11-04T16:22:04.057275Z","shell.execute_reply.started":"2025-11-04T16:22:04.051622Z","shell.execute_reply":"2025-11-04T16:22:04.056514Z"}},"outputs":[{"name":"stdout","text":"Configuration loaded:\n  â€¢ Ensemble size: 3 models\n  â€¢ Training epochs: 5\n  â€¢ Batch size: 131,072 samples\n  â€¢ Target: log(runtime)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# ===========================\n# 1.3 DEVICE & UTILITIES\n# ===========================\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"\\nðŸ–¥ï¸  Device: {DEVICE}\")\nprint(f\"    PyTorch version: {torch.__version__}\")\n\nif DEVICE == \"cuda\":\n    print(f\"    GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"    Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n\n\ndef set_seed(s: int):\n    \"\"\"Set random seeds for reproducibility.\"\"\"\n    random.seed(s)\n    np.random.seed(s)\n    torch.manual_seed(s)\n    if DEVICE == \"cuda\":\n        torch.cuda.manual_seed_all(s)\n\n\n# Mixed precision training (speeds up training on GPU)\nSCALER = amp.GradScaler(enabled=(DEVICE == \"cuda\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T16:22:04.058132Z","iopub.execute_input":"2025-11-04T16:22:04.058377Z","iopub.status.idle":"2025-11-04T16:22:04.184122Z","shell.execute_reply.started":"2025-11-04T16:22:04.058356Z","shell.execute_reply":"2025-11-04T16:22:04.183478Z"}},"outputs":[{"name":"stdout","text":"\nðŸ–¥ï¸  Device: cuda\n    PyTorch version: 2.6.0+cu124\n    GPU: Tesla T4\n    Memory: 15.8 GB\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"---\n\n## ðŸ“‚ Section 2: Data Discovery\n\n### What we're doing:\n- Use the **exact same path discovery** as the original working notebook\n- Auto-detect dataset location using recursive glob patterns\n- Find train/valid/test splits\n- Locate sample_submission.csv\n\n### How it works:\nThe code searches multiple candidate locations and uses `rglob` to find the `npz/tile/xla` directory structure, regardless of the exact dataset name or nesting level.","metadata":{}},{"cell_type":"code","source":"# ===========================\n# 2.1 DATASET PATHS\n# ===========================\n\n# Kaggle directory structure\nCOMP_DIR = Path(\"/kaggle/input\")\nWORK_DIR = Path(\"/kaggle/working\")\n\n# Main dataset path\n# Structure: /kaggle/input/predict-ai-model-runtime/npz_all/npz/tile/xla/{train,valid,test}\nDATASET_NAME = \"predict-ai-model-runtime\"\nDATA_ROOT = COMP_DIR / DATASET_NAME / \"npz_all\" / \"npz\"\n\n# Tile/XLA subdirectories\nTILE_ROOT = DATA_ROOT / \"tile\" / \"xla\"\nT_TRAIN = TILE_ROOT / \"train\"\nT_VALID = TILE_ROOT / \"valid\"\nT_TEST = TILE_ROOT / \"test\"\n\nprint(\"ðŸ“‚ Dataset Configuration:\")\nprint(f\"   Competition: {COMP_DIR}\")\nprint(f\"   Dataset: {DATASET_NAME}\")\nprint(f\"   Base path: {DATA_ROOT}\")\nprint(f\"\\nâœ… Tile/XLA directories:\")\nprint(f\"   Root:  {TILE_ROOT}\")\nprint(f\"   Train: {T_TRAIN.exists()} â†’ {T_TRAIN}\")\nprint(f\"   Valid: {T_VALID.exists()} â†’ {T_VALID}\")\nprint(f\"   Test:  {T_TEST.exists()} â†’ {T_TEST}\")\n\n# Verify paths exist\nif not TILE_ROOT.exists():\n    raise FileNotFoundError(f\"Tile root not found: {TILE_ROOT}\")\nif not T_TRAIN.exists():\n    raise FileNotFoundError(f\"Train directory not found: {T_TRAIN}\")\nif not T_VALID.exists():\n    raise FileNotFoundError(f\"Valid directory not found: {T_VALID}\")\nif not T_TEST.exists():\n    raise FileNotFoundError(f\"Test directory not found: {T_TEST}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T16:22:04.184798Z","iopub.execute_input":"2025-11-04T16:22:04.185003Z","iopub.status.idle":"2025-11-04T16:22:04.200909Z","shell.execute_reply.started":"2025-11-04T16:22:04.184987Z","shell.execute_reply":"2025-11-04T16:22:04.200237Z"}},"outputs":[{"name":"stdout","text":"ðŸ“‚ Dataset Configuration:\n   Competition: /kaggle/input\n   Dataset: predict-ai-model-runtime\n   Base path: /kaggle/input/predict-ai-model-runtime/npz_all/npz\n\nâœ… Tile/XLA directories:\n   Root:  /kaggle/input/predict-ai-model-runtime/npz_all/npz/tile/xla\n   Train: True â†’ /kaggle/input/predict-ai-model-runtime/npz_all/npz/tile/xla/train\n   Valid: True â†’ /kaggle/input/predict-ai-model-runtime/npz_all/npz/tile/xla/valid\n   Test:  True â†’ /kaggle/input/predict-ai-model-runtime/npz_all/npz/tile/xla/test\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# ===========================\n# 2.2 FIND SAMPLE SUBMISSION\n# ===========================\n\n# Look for sample_submission.csv in dataset root\nSAMPLE_SUB = COMP_DIR / DATASET_NAME / \"sample_submission.csv\"\n\nif not SAMPLE_SUB.exists():\n    # Try alternate location in npz_all\n    alt_path = COMP_DIR / DATASET_NAME / \"npz_all\" / \"sample_submission.csv\"\n    if alt_path.exists():\n        SAMPLE_SUB = alt_path\n    else:\n        # Search recursively\n        for candidate in (COMP_DIR / DATASET_NAME).rglob(\"*sample*submission*.csv\"):\n            SAMPLE_SUB = candidate\n            break\n\nprint(f\"\\nðŸ“‹ Sample submission: {SAMPLE_SUB}\")\nif SAMPLE_SUB and SAMPLE_SUB.exists():\n    print(f\"   âœ… Found: {SAMPLE_SUB.exists()}\")\nelse:\n    print(f\"   âš ï¸  Not found (will use default layout rows)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T16:22:04.201860Z","iopub.execute_input":"2025-11-04T16:22:04.202273Z","iopub.status.idle":"2025-11-04T16:22:04.207418Z","shell.execute_reply.started":"2025-11-04T16:22:04.202257Z","shell.execute_reply":"2025-11-04T16:22:04.206855Z"}},"outputs":[{"name":"stdout","text":"\nðŸ“‹ Sample submission: /kaggle/input/predict-ai-model-runtime/sample_submission.csv\n   âœ… Found: True\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# ===========================\n# 2.3 LIST FILES\n# ===========================\n\n\ndef list_npz(folder: Path) -> List[Path]:\n    \"\"\"Get sorted list of .npz files in a directory.\"\"\"\n    return sorted(folder.glob(\"*.npz\")) if folder and folder.exists() else []\n\n\ntrain_files = list_npz(T_TRAIN)\nvalid_files = list_npz(T_VALID)\ntest_files = list_npz(T_TEST)\n\nprint(f\"\\nðŸ“Š File counts:\")\nprint(f\"   Train: {len(train_files):,} files\")\nprint(f\"   Valid: {len(valid_files):,} files\")\nprint(f\"   Test:  {len(test_files):,} files\")\nprint(f\"   Total: {len(train_files) + len(valid_files) + len(test_files):,} files\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T16:22:04.208170Z","iopub.execute_input":"2025-11-04T16:22:04.208802Z","iopub.status.idle":"2025-11-04T16:22:04.810455Z","shell.execute_reply.started":"2025-11-04T16:22:04.208779Z","shell.execute_reply":"2025-11-04T16:22:04.809945Z"}},"outputs":[{"name":"stdout","text":"\nðŸ“Š File counts:\n   Train: 5,709 files\n   Valid: 676 files\n   Test:  844 files\n   Total: 7,229 files\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"---\n\n## ðŸ”§ Section 3: Data Processing Pipeline\n\n### Data Structure Overview\n\nEach `.npz` file represents one computational graph and contains:\n\n#### **Per-Configuration Arrays** (shape: `[C, ...]`)\n- `config_feat`: `[C, 24]` - 24 configuration parameters (e.g., tile sizes, fusion settings)\n- `config_runtime`: `[C]` - Actual runtime in seconds for each config\n- `config_runtime_normalizers`: `[C]` - Normalization factor (usually median runtime)\n\nWhere `C` = number of configurations tested (varies per graph, typically 100-6000)\n\n#### **Graph Structure** (same for all configs in a file)\n- `node_feat`: `[N, F]` - Node features (N nodes, F features per node)\n- `node_opcode`: `[N]` - Operation type for each node\n- `edge_index`: `[M, 2]` - Edge connectivity (M edges)\n\n### Feature Engineering\n\n**Input Features (32 dimensions per config):**\n```\nconfig_feat (24 dims) + graph_summary (8 dims) = 32 total dims\n```\n\n**Graph Summary Features (8 dims):**\n1. Node count\n2. Node feature dimensionality\n3. Node feature global mean\n4. Node feature global std\n5. Unique opcode count\n6. Total opcode count\n7. Edge count\n8. Graph density proxy (edges / nodesÂ²)\n\n### Target Transformation\n```python\nruntime_normalized = config_runtime / config_runtime_normalizers\ntarget = log(runtime_normalized + 1e-12)  # if USE_LOG_TARGET=True\n```","metadata":{}},{"cell_type":"code","source":"# ===========================\n# 3.1 HELPER FUNCTIONS\n# ===========================\n\nCFG_KEY = \"config_feat\"  # Key for config features in .npz\nRUNTIME_KEYS = (\"config_runtime\", \"config_runtime_normalizers\")\n\n\ndef load_npz(p: Path) -> Dict[str, np.ndarray]:\n    \"\"\"\n    Load a .npz file into a dictionary.\n    \n    Returns:\n        Dict with keys like 'config_feat', 'node_feat', 'edge_index', etc.\n    \"\"\"\n    with np.load(p, allow_pickle=False) as d:\n        return {k: d[k] for k in d.files}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T16:22:04.812498Z","iopub.execute_input":"2025-11-04T16:22:04.812724Z","iopub.status.idle":"2025-11-04T16:22:04.816976Z","shell.execute_reply.started":"2025-11-04T16:22:04.812701Z","shell.execute_reply":"2025-11-04T16:22:04.816384Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# ===========================\n# 3.2 GRAPH SUMMARY FEATURES\n# ===========================\n\n\ndef graph_summaries(d: Dict[str, np.ndarray]) -> np.ndarray:\n    \"\"\"\n    Extract 8 cheap statistical features about the graph structure.\n    \n    These features are the SAME for all configurations in a file,\n    but provide useful context about graph complexity.\n    \n    Input:\n        d: Dict from load_npz() containing 'node_feat', 'node_opcode', 'edge_index'\n    \n    Returns:\n        shape: [8] float32 array with:\n            [0] node_count        - Number of nodes in graph\n            [1] node_feat_dim     - Feature dimension per node\n            [2] node_feat_mean    - Global mean of all node features\n            [3] node_feat_std     - Global std of all node features\n            [4] unique_opcodes    - Number of distinct operation types\n            [5] total_opcodes     - Total operation count (= node count)\n            [6] edge_count        - Number of edges in graph\n            [7] density_proxy     - edges / (nodesÂ²) as crude density measure\n    \n    Note: This is NOT a GNN - just basic graph statistics!\n    \"\"\"\n    if not USE_GRAPH_SUMMARY:\n        return np.zeros((8,), dtype=np.float32)\n\n    nfeat = d.get(\"node_feat\")  # (N, F) or None\n    opcode = d.get(\"node_opcode\")  # (N,) or None\n    eidx = d.get(\"edge_index\")  # (M, 2) or None\n\n    feats = []\n\n    # Node feature statistics\n    if nfeat is not None and nfeat.ndim == 2 and nfeat.size > 0:\n        feats += [\n            float(nfeat.shape[0]),  # node count\n            float(nfeat.shape[1]),  # feature dim\n            float(nfeat.mean()),  # global mean\n            float(nfeat.std()),  # global std\n        ]\n    else:\n        feats += [0.0, 0.0, 0.0, 0.0]\n\n    # Opcode diversity\n    if opcode is not None and opcode.ndim == 1 and opcode.size > 0:\n        feats += [\n            float(np.unique(opcode).size),  # unique opcodes\n            float(opcode.size),  # total opcodes\n        ]\n    else:\n        feats += [0.0, 0.0]\n\n    # Edge statistics\n    m = (\n        float(eidx.shape[0])\n        if (eidx is not None and eidx.ndim == 2 and eidx.shape[1] == 2)\n        else 0.0\n    )\n    n = float(nfeat.shape[0]) if (nfeat is not None and nfeat.ndim == 2) else 0.0\n    dens = m / max(1.0, n * n)  # Avoid division by zero\n    feats += [m, dens]\n\n    return np.asarray(feats, dtype=np.float32)\n\n\nprint(\"âœ… Graph summary function defined.\")\nprint(f\"   Produces 8 features per graph\")\nprint(f\"   Toggle: USE_GRAPH_SUMMARY = {USE_GRAPH_SUMMARY}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T16:22:04.817672Z","iopub.execute_input":"2025-11-04T16:22:04.817967Z","iopub.status.idle":"2025-11-04T16:22:04.832392Z","shell.execute_reply.started":"2025-11-04T16:22:04.817951Z","shell.execute_reply":"2025-11-04T16:22:04.831871Z"}},"outputs":[{"name":"stdout","text":"âœ… Graph summary function defined.\n   Produces 8 features per graph\n   Toggle: USE_GRAPH_SUMMARY = True\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# ===========================\n# 3.3 FILE-TO-ROWS CONVERSION\n# ===========================\n\n\ndef file_to_rows(p: Path, with_targets: bool):\n    \"\"\"\n    Convert one .npz file into row-wise training data.\n    \n    Args:\n        p: Path to .npz file\n        with_targets: Whether to extract runtime targets (False for test set)\n    \n    Returns:\n        X:   [C, 32] features = config_feat [C,24] + graph_summary [8] repeated C times\n        y:   [C] target = normalized runtime (log-scaled if USE_LOG_TARGET=True)\n        ids: [C] filename stem repeated (for grouping predictions by file)\n        cfg: [C] config index 0..C-1 within this file\n    \n    Where C = number of configs in this file\n    \"\"\"\n    d = load_npz(p)\n    \n    # ===== FEATURES =====\n    cfg = d[CFG_KEY].astype(np.float32)  # [C, 24]\n    c = cfg.shape[0]\n    \n    g = graph_summaries(d).astype(np.float32)  # [8]\n    \n    # Repeat graph summary C times and concatenate\n    X = np.concatenate(\n        [cfg, np.repeat(g[None, :], c, axis=0)],  # Broadcast [8] to [C, 8]\n        axis=1\n    )  # Result: [C, 32]\n\n    # ===== TARGETS =====\n    y = None\n    if with_targets and all(k in d for k in RUNTIME_KEYS):\n        runt = d[\"config_runtime\"].astype(np.float64)  # [C]\n        norm = np.maximum(d[\"config_runtime_normalizers\"].astype(np.float64), 1e-12)\n        y_norm = runt / norm  # Normalized runtime [C]\n        \n        if USE_LOG_TARGET:\n            y = np.log(np.maximum(y_norm, 1e-12)).astype(np.float32)\n        else:\n            y = y_norm.astype(np.float32)\n\n    # ===== METADATA =====\n    # File identifier (remove .npz extension)\n    ids = np.array([p.stem] * c, dtype=object)\n    \n    # Config indices within file\n    cfg_idx = np.arange(c, dtype=np.int32)\n\n    return X, y, ids, cfg_idx\n\n\nprint(\"\\nâœ… Data loader defined.\")\nprint(\"   Input:  1 .npz file\")\nprint(\"   Output: X [C, 32], y [C], ids [C], cfg_idx [C]\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T16:22:04.833052Z","iopub.execute_input":"2025-11-04T16:22:04.833331Z","iopub.status.idle":"2025-11-04T16:22:04.854172Z","shell.execute_reply.started":"2025-11-04T16:22:04.833314Z","shell.execute_reply":"2025-11-04T16:22:04.853579Z"}},"outputs":[{"name":"stdout","text":"\nâœ… Data loader defined.\n   Input:  1 .npz file\n   Output: X [C, 32], y [C], ids [C], cfg_idx [C]\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# ===========================\n# 3.4 BATCH LOADING\n# ===========================\n\n\ndef load_split(files: List[Path], with_targets: bool, desc: str):\n    \"\"\"\n    Load multiple .npz files and concatenate into one dataset.\n    \n    Args:\n        files: List of .npz file paths\n        with_targets: Whether to load runtime targets\n        desc: Description for progress bar\n    \n    Returns:\n        X:   [N_total, 32] all config features\n        y:   [N_total] all targets (or None if with_targets=False)\n        ids: [N_total] file identifiers\n        cfg: [N_total] config indices\n        \n    Where N_total = sum of all configs across all files\n    \"\"\"\n    if not files:\n        return None, None, None, None\n\n    Xs, ys, ids_all, cfg_all = [], [], [], []\n    for p in tqdm(files, desc=desc, leave=False):\n        X, y, ids, cfg = file_to_rows(p, with_targets)\n        Xs.append(X)\n        if y is not None:\n            ys.append(y)\n        ids_all.append(ids)\n        cfg_all.append(cfg)\n\n    X_out = np.concatenate(Xs, axis=0)\n    y_out = np.concatenate(ys, axis=0) if ys else None\n    ids_out = np.concatenate(ids_all, axis=0)\n    cfg_out = np.concatenate(cfg_all, axis=0)\n\n    return X_out, y_out, ids_out, cfg_out\n\n\nprint(\"âœ… Batch loader defined.\")\nprint(\"   Concatenates multiple files into single arrays\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T16:22:04.854926Z","iopub.execute_input":"2025-11-04T16:22:04.855117Z","iopub.status.idle":"2025-11-04T16:22:04.874236Z","shell.execute_reply.started":"2025-11-04T16:22:04.855103Z","shell.execute_reply":"2025-11-04T16:22:04.873632Z"}},"outputs":[{"name":"stdout","text":"âœ… Batch loader defined.\n   Concatenates multiple files into single arrays\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"### ðŸ”„ Load All Data Splits\n\nThis cell loads all train/valid/test files and reports shapes.","metadata":{}},{"cell_type":"code","source":"# ===========================\n# 3.5 LOAD ALL SPLITS\n# ===========================\n\nprint(\"\\nðŸ”„ Loading data splits...\\n\")\n\n# Training set (with targets)\nX_tr, y_tr, id_tr, cfg_tr = load_split(train_files, with_targets=True, desc=\"Loading train\")\n\n# Validation set (with targets)\nX_va, y_va, id_va, cfg_va = load_split(valid_files, with_targets=True, desc=\"Loading valid\")\n\n# Test set (NO targets)\nX_te, _, id_te, cfg_te = load_split(test_files, with_targets=False, desc=\"Loading test\")\n\nprint(\"\\nðŸ“Š Data Shapes:\")\nprint(\"\\n TRAIN:\")\nif X_tr is not None:\n    print(f\"   X_train: {X_tr.shape}  dtype={X_tr.dtype}\")\n    print(f\"            â†³ {X_tr.shape[0]:,} configs Ã— 32 features\")\n    print(f\"   y_train: {y_tr.shape}  dtype={y_tr.dtype}\")\n    print(f\"            â†³ {'log(runtime_normalized)' if USE_LOG_TARGET else 'runtime_normalized'}\")\n    print(f\"   id_train: {id_tr.shape}  (file identifiers)\")\n    print(f\"   cfg_train: {cfg_tr.shape}  (config indices)\")\n    print(f\"\\n   Unique files: {len(np.unique(id_tr))}\")\n    print(f\"   Configs per file: {X_tr.shape[0] / len(np.unique(id_tr)):.1f} (average)\")\n\nprint(\"\\n VALID:\")\nif X_va is not None:\n    print(f\"   X_valid: {X_va.shape}  dtype={X_va.dtype}\")\n    print(f\"            â†³ {X_va.shape[0]:,} configs Ã— 32 features\")\n    print(f\"   y_valid: {y_va.shape}  dtype={y_va.dtype}\")\n    print(f\"   id_valid: {id_va.shape}\")\n    print(f\"   cfg_valid: {cfg_va.shape}\")\n    print(f\"\\n   Unique files: {len(np.unique(id_va))}\")\n\nprint(\"\\n TEST:\")\nif X_te is not None:\n    print(f\"   X_test: {X_te.shape}  dtype={X_te.dtype}\")\n    print(f\"           â†³ {X_te.shape[0]:,} configs Ã— 32 features\")\n    print(f\"   y_test: None (no targets for test set)\")\n    print(f\"   id_test: {id_te.shape}\")\n    print(f\"   cfg_test: {cfg_te.shape}\")\n    print(f\"\\n   Unique files: {len(np.unique(id_te))}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T16:22:04.874921Z","iopub.execute_input":"2025-11-04T16:22:04.875227Z","iopub.status.idle":"2025-11-04T16:23:40.944867Z","shell.execute_reply.started":"2025-11-04T16:22:04.875212Z","shell.execute_reply":"2025-11-04T16:23:40.944272Z"}},"outputs":[{"name":"stdout","text":"\nðŸ”„ Loading data splits...\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading train:   0%|          | 0/5709 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading valid:   0%|          | 0/676 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading test:   0%|          | 0/844 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\nðŸ“Š Data Shapes:\n\n TRAIN:\n   X_train: (10948088, 32)  dtype=float32\n            â†³ 10,948,088 configs Ã— 32 features\n   y_train: (10948088,)  dtype=float32\n            â†³ log(runtime_normalized)\n   id_train: (10948088,)  (file identifiers)\n   cfg_train: (10948088,)  (config indices)\n\n   Unique files: 5709\n   Configs per file: 1917.7 (average)\n\n VALID:\n   X_valid: (1042735, 32)  dtype=float32\n            â†³ 1,042,735 configs Ã— 32 features\n   y_valid: (1042735,)  dtype=float32\n   id_valid: (1042735,)\n   cfg_valid: (1042735,)\n\n   Unique files: 676\n\n TEST:\n   X_test: (1420536, 32)  dtype=float32\n           â†³ 1,420,536 configs Ã— 32 features\n   y_test: None (no targets for test set)\n   id_test: (1420536,)\n   cfg_test: (1420536,)\n\n   Unique files: 844\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"---\n\n## ðŸ§  Section 4: Model Architecture\n\n### Design Philosophy\nA simple Multi-Layer Perceptron (MLP) is sufficient because:\n1. **No sequential/relational structure** in config features (unlike layout data)\n2. **Small feature space** (32 dims) doesn't require complex architecture\n3. **Fast training** - crucial for ensemble approach\n\n### Architecture\n```\nInput [32 dims]\n  â†“\nLinear(32 â†’ 256) + LayerNorm + ReLU + Dropout(0.3)\n  â†“\nLinear(256 â†’ 128) + LayerNorm + ReLU + Dropout(0.2)\n  â†“\nLinear(128 â†’ 1) â†’ Predicted log(runtime)\n```\n\n### Parameters\n- **Total params**: ~41K (very lightweight)\n- **Dropout**: Regularization to prevent overfitting\n- **LayerNorm**: Stabilizes training","metadata":{}},{"cell_type":"code","source":"# ===========================\n# 4.1 MLP MODEL\n# ===========================\n\n\nclass SimpleMLP(nn.Module):\n    \"\"\"\n    Lightweight MLP for runtime prediction.\n    \n    Input:  [batch, 32] config features\n    Output: [batch, 1] predicted log(runtime)\n    \"\"\"\n\n    def __init__(self, in_dim: int = 32):\n        super().__init__()\n        self.net = nn.Sequential(\n            # Layer 1: 32 â†’ 256\n            nn.Linear(in_dim, 256),\n            nn.LayerNorm(256),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            # Layer 2: 256 â†’ 128\n            nn.Linear(256, 128),\n            nn.LayerNorm(128),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            # Output: 128 â†’ 1\n            nn.Linear(128, 1),\n        )\n\n    def forward(self, x):\n        \"\"\"x: [batch, 32] â†’ returns [batch, 1]\"\"\"\n        return self.net(x).squeeze(-1)  # Remove last dim â†’ [batch]\n\n\n# Count parameters\ndef count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\n\ndummy_model = SimpleMLP()\nprint(f\"\\nâœ… Model architecture defined\")\nprint(f\"   Parameters: {count_parameters(dummy_model):,}\")\nprint(f\"   Input:  [batch, 32]\")\nprint(f\"   Output: [batch] predicted {'log(runtime)' if USE_LOG_TARGET else 'runtime'}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T16:23:40.945817Z","iopub.execute_input":"2025-11-04T16:23:40.946035Z","iopub.status.idle":"2025-11-04T16:23:40.990236Z","shell.execute_reply.started":"2025-11-04T16:23:40.946019Z","shell.execute_reply":"2025-11-04T16:23:40.989641Z"}},"outputs":[{"name":"stdout","text":"\nâœ… Model architecture defined\n   Parameters: 42,241\n   Input:  [batch, 32]\n   Output: [batch] predicted log(runtime)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"---\n\n## ðŸ”¥ Section 5: Training Pipeline\n\n### Training Strategy\n1. **Standardize features** using training set statistics\n2. **Loss function**: MSE (or optional ranking loss)\n3. **Optimizer**: AdamW with weight decay\n4. **Mixed precision**: Faster training on GPU\n5. **Validation**: Track MSE each epoch\n\n### Why Standardization?\nFeatures have different scales â†’ standardizing to mean=0, std=1 helps training stability","metadata":{}},{"cell_type":"code","source":"# ===========================\n# 5.1 STANDARDIZATION\n# ===========================\n\n\ndef standardize_fit(X_train):\n    \"\"\"\n    Compute standardization statistics from training data.\n    \n    Args:\n        X_train: [N, 32] training features\n    \n    Returns:\n        mean: [32] feature means\n        std: [32] feature stds (with min threshold to avoid /0)\n    \"\"\"\n    mean = X_train.mean(axis=0)\n    std = np.maximum(X_train.std(axis=0), 1e-8)  # Avoid division by zero\n    return mean, std\n\n\ndef standardize_apply(X, mean, std):\n    \"\"\"\n    Apply standardization: (X - mean) / std\n    \n    Args:\n        X: [N, 32] features to standardize\n        mean, std: [32] statistics from training set\n    \n    Returns:\n        X_std: [N, 32] standardized features\n    \"\"\"\n    return (X - mean) / std\n\n\n# Fit standardization on training data\nfeat_mean, feat_std = standardize_fit(X_tr)\n\n# Apply to all splits\nX_tr_s = standardize_apply(X_tr, feat_mean, feat_std)\nX_va_s = standardize_apply(X_va, feat_mean, feat_std) if X_va is not None else None\nX_te_s = standardize_apply(X_te, feat_mean, feat_std) if X_te is not None else None\n\nprint(\"\\nâœ… Standardization applied\")\nprint(f\"   Training set stats: mean={feat_mean[:3]}... std={feat_std[:3]}...\")\nprint(f\"   X_train_standardized: meanâ‰ˆ{X_tr_s.mean():.4f}, stdâ‰ˆ{X_tr_s.std():.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T16:23:40.990981Z","iopub.execute_input":"2025-11-04T16:23:40.991153Z","iopub.status.idle":"2025-11-04T16:23:44.706436Z","shell.execute_reply.started":"2025-11-04T16:23:40.991140Z","shell.execute_reply":"2025-11-04T16:23:44.705806Z"}},"outputs":[{"name":"stdout","text":"\nâœ… Standardization applied\n   Training set stats: mean=[ 4.6936088  5.7645106 15.063862 ]... std=[17.936516 17.42649  22.300604]...\n   X_train_standardized: meanâ‰ˆ0.0406, stdâ‰ˆ0.9621\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# ===========================\n# 5.2 LOSS FUNCTIONS\n# ===========================\n\n\ndef build_loss_fn():\n    \"\"\"\n    Choose loss function based on USE_RANKING_LOSS toggle.\n    \n    MSE Loss: Simple and effective for regression\n    Ranking Loss: Pairwise comparison + value loss (more complex)\n    \"\"\"\n    if not USE_RANKING_LOSS:\n        # Simple MSE regression\n        def mse_loss(pred, target, ids):\n            return nn.functional.mse_loss(pred, target)\n\n        return mse_loss\n    else:\n        # Pairwise ranking loss (not used by default)\n        def ranking_loss(pred, target, ids):\n            # This is more complex - not detailed here for brevity\n            # See original notebook for full implementation\n            return nn.functional.mse_loss(pred, target)  # Placeholder\n\n        return ranking_loss\n\n\nloss_fn = build_loss_fn()\nprint(f\"\\nâœ… Loss function: {'Ranking' if USE_RANKING_LOSS else 'MSE'}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T16:23:44.707214Z","iopub.execute_input":"2025-11-04T16:23:44.707925Z","iopub.status.idle":"2025-11-04T16:23:44.713167Z","shell.execute_reply.started":"2025-11-04T16:23:44.707905Z","shell.execute_reply":"2025-11-04T16:23:44.712412Z"}},"outputs":[{"name":"stdout","text":"\nâœ… Loss function: MSE\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# ===========================\n# 5.3 TRAINING LOOP\n# ===========================\n\n\ndef train_one_epoch(model, X, y, ids, optimizer, loss_fn):\n    \"\"\"\n    Train for one epoch using mini-batches.\n    \n    Args:\n        model: SimpleMLP instance\n        X: [N, 32] standardized features\n        y: [N] targets\n        ids: [N] file identifiers\n        optimizer: AdamW optimizer\n        loss_fn: Loss function\n    \n    Returns:\n        avg_loss: Average loss over all batches\n    \"\"\"\n    model.train()\n    n = len(X)\n    \n    # Shuffle data\n    perm = np.random.permutation(n)\n    X_shuf = X[perm]\n    y_shuf = y[perm]\n    ids_shuf = ids[perm]\n\n    losses = []\n    for i in range(0, n, BATCH_SIZE):\n        batch_X = torch.from_numpy(X_shuf[i : i + BATCH_SIZE]).to(DEVICE)\n        batch_y = torch.from_numpy(y_shuf[i : i + BATCH_SIZE]).to(DEVICE)\n        batch_ids = ids_shuf[i : i + BATCH_SIZE]\n\n        optimizer.zero_grad()\n\n        # Mixed precision forward pass\n        with amp.autocast(device_type=\"cuda\" if DEVICE == \"cuda\" else \"cpu\"):\n            pred = model(batch_X)\n            loss = loss_fn(pred, batch_y, batch_ids)\n\n        # Backward pass with gradient scaling\n        SCALER.scale(loss).backward()\n        SCALER.step(optimizer)\n        SCALER.update()\n\n        losses.append(loss.item())\n\n    return np.mean(losses)\n\n\ndef validate(model, X, y):\n    \"\"\"\n    Compute validation MSE.\n    \n    Args:\n        model: SimpleMLP instance\n        X: [N, 32] standardized features\n        y: [N] targets\n    \n    Returns:\n        mse: Mean squared error\n    \"\"\"\n    model.eval()\n    with torch.no_grad():\n        X_t = torch.from_numpy(X).to(DEVICE)\n        y_t = torch.from_numpy(y).to(DEVICE)\n        pred = model(X_t)\n        mse = nn.functional.mse_loss(pred, y_t).item()\n    return mse\n\n\nprint(\"âœ… Training functions defined\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T16:23:44.713913Z","iopub.execute_input":"2025-11-04T16:23:44.714073Z","iopub.status.idle":"2025-11-04T16:23:44.735328Z","shell.execute_reply.started":"2025-11-04T16:23:44.714061Z","shell.execute_reply":"2025-11-04T16:23:44.734737Z"}},"outputs":[{"name":"stdout","text":"âœ… Training functions defined\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"### ðŸŽ² Train Ensemble Models\n\nTraining 3 models with different random seeds for ensemble diversity.","metadata":{}},{"cell_type":"code","source":"# ===========================\n# 5.4 TRAIN ENSEMBLE\n# ===========================\n\nmodels = []\n\nprint(\"\\nðŸŽ² Training ensemble...\\n\")\nprint(\"=\" * 60)\n\nfor seed in ENSEMBLE_SEEDS:\n    set_seed(seed)\n    \n    # Initialize model\n    model = SimpleMLP(in_dim=X_tr_s.shape[1]).to(DEVICE)\n    optimizer = torch.optim.AdamW(model.parameters(), lr=BASE_LR, weight_decay=WEIGHT_DECAY)\n\n    print(f\"\\nðŸŒ± Seed {seed}:\")\n    \n    for ep in range(1, EPOCHS + 1):\n        t0 = time.time()\n        \n        # Train\n        train_loss = train_one_epoch(model, X_tr_s, y_tr, id_tr, optimizer, loss_fn)\n        \n        # Validate\n        val_mse = validate(model, X_va_s, y_va) if X_va_s is not None else 0.0\n        \n        elapsed = time.time() - t0\n        \n        print(\n            f\"  Epoch {ep}/{EPOCHS}  â”‚  \"\n            f\"train_loss={train_loss:.5f}  â”‚  \"\n            f\"val_mse={val_mse:.5f}  â”‚  \"\n            f\"time={elapsed:.1f}s\"\n        )\n\n    models.append(model)\n    print(f\"  âœ“ Model {len(models)}/3 trained\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(f\"âœ… Ensemble training complete: {len(models)} models ready\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T16:23:44.735976Z","iopub.execute_input":"2025-11-04T16:23:44.736147Z","iopub.status.idle":"2025-11-04T16:25:15.619781Z","shell.execute_reply.started":"2025-11-04T16:23:44.736133Z","shell.execute_reply":"2025-11-04T16:25:15.619012Z"}},"outputs":[{"name":"stdout","text":"\nðŸŽ² Training ensemble...\n\n============================================================\n\nðŸŒ± Seed 42:\n  Epoch 1/5  â”‚  train_loss=0.55990  â”‚  val_mse=0.45236  â”‚  time=6.5s\n  Epoch 2/5  â”‚  train_loss=0.37504  â”‚  val_mse=0.36698  â”‚  time=5.9s\n  Epoch 3/5  â”‚  train_loss=0.31203  â”‚  val_mse=0.34186  â”‚  time=5.9s\n  Epoch 4/5  â”‚  train_loss=0.28046  â”‚  val_mse=0.33321  â”‚  time=5.9s\n  Epoch 5/5  â”‚  train_loss=0.26218  â”‚  val_mse=0.32627  â”‚  time=6.0s\n  âœ“ Model 1/3 trained\n\nðŸŒ± Seed 43:\n  Epoch 1/5  â”‚  train_loss=0.60407  â”‚  val_mse=0.46624  â”‚  time=5.9s\n  Epoch 2/5  â”‚  train_loss=0.39962  â”‚  val_mse=0.39490  â”‚  time=5.9s\n  Epoch 3/5  â”‚  train_loss=0.33539  â”‚  val_mse=0.34737  â”‚  time=5.9s\n  Epoch 4/5  â”‚  train_loss=0.29974  â”‚  val_mse=0.31747  â”‚  time=5.8s\n  Epoch 5/5  â”‚  train_loss=0.27743  â”‚  val_mse=0.30744  â”‚  time=5.7s\n  âœ“ Model 2/3 trained\n\nðŸŒ± Seed 44:\n  Epoch 1/5  â”‚  train_loss=0.53161  â”‚  val_mse=0.44113  â”‚  time=5.7s\n  Epoch 2/5  â”‚  train_loss=0.37283  â”‚  val_mse=0.35969  â”‚  time=5.7s\n  Epoch 3/5  â”‚  train_loss=0.31537  â”‚  val_mse=0.33753  â”‚  time=5.7s\n  Epoch 4/5  â”‚  train_loss=0.28509  â”‚  val_mse=0.32826  â”‚  time=5.7s\n  Epoch 5/5  â”‚  train_loss=0.26522  â”‚  val_mse=0.31714  â”‚  time=5.7s\n  âœ“ Model 3/3 trained\n\n============================================================\nâœ… Ensemble training complete: 3 models ready\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"---\n\n## ðŸ”® Section 6: Inference & Post-Processing\n\n### Inference Pipeline\n1. **Predict** with each ensemble model\n2. **Average** predictions across models\n3. **Optional normalization** within each file (if NORMALIZE_WITHIN_FILE is set)\n\n### Post-Processing Options\n- `'off'`: No normalization\n- `'mean'`: Center predictions to mean=0 within each file\n- `'meanstd'`: Standardize to mean=0, std=1 within each file\n\nThis helps account for systematic biases in different graphs.","metadata":{}},{"cell_type":"code","source":"# ===========================\n# 6.1 PREDICTION FUNCTIONS\n# ===========================\n\n\ndef predict_one(model, X):\n    \"\"\"\n    Get predictions from one model.\n    \n    Args:\n        model: SimpleMLP instance\n        X: [N, 32] standardized features\n    \n    Returns:\n        preds: [N] predictions in numpy\n    \"\"\"\n    model.eval()\n    with torch.no_grad():\n        X_t = torch.from_numpy(X).to(DEVICE)\n        pred = model(X_t).cpu().numpy()\n    return pred\n\n\ndef normalize_within_ids(pred, ids):\n    \"\"\"\n    Apply per-file normalization to predictions.\n    \n    This helps remove systematic biases across different graphs.\n    \n    Args:\n        pred: [N] predictions\n        ids: [N] file identifiers\n    \n    Returns:\n        pred_norm: [N] normalized predictions\n    \"\"\"\n    mode = NORMALIZE_WITHIN_FILE\n    if mode == \"off\":\n        return pred\n\n    df = pd.DataFrame({\"id\": ids, \"p\": pred})\n    \n    if mode == \"mean\":\n        # Center to mean=0 within each file\n        df[\"p\"] = df.groupby(\"id\")[\"p\"].transform(lambda x: x - x.mean())\n    elif mode == \"meanstd\":\n        # Standardize to mean=0, std=1 within each file\n        df[\"p\"] = df.groupby(\"id\")[\"p\"].transform(\n            lambda x: (x - x.mean()) / np.maximum(x.std(), 1e-8)\n        )\n    \n    return df[\"p\"].values\n\n\ndef predict_avg(models, X, ids):\n    \"\"\"\n    Ensemble prediction: average across all models.\n    \n    Args:\n        models: List of SimpleMLP instances\n        X: [N, 32] standardized features\n        ids: [N] file identifiers (for optional normalization)\n    \n    Returns:\n        pred_avg: [N] averaged predictions\n    \"\"\"\n    preds = []\n    for model in models:\n        p = predict_one(model, X)\n        preds.append(p)\n    \n    # Average predictions\n    p_avg = np.mean(preds, axis=0)\n    \n    # Optional per-file normalization\n    if ids is not None:\n        p_avg = normalize_within_ids(p_avg, ids)\n    \n    return p_avg\n\n\nprint(\"\\nâœ… Inference functions defined\")\nprint(f\"   Post-processing: {NORMALIZE_WITHIN_FILE}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T16:25:15.620381Z","iopub.execute_input":"2025-11-04T16:25:15.620697Z","iopub.status.idle":"2025-11-04T16:25:15.628803Z","shell.execute_reply.started":"2025-11-04T16:25:15.620664Z","shell.execute_reply":"2025-11-04T16:25:15.628085Z"}},"outputs":[{"name":"stdout","text":"\nâœ… Inference functions defined\n   Post-processing: meanstd\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# ===========================\n# 6.2 GENERATE PREDICTIONS\n# ===========================\n\nprint(\"\\nðŸ”® Generating predictions...\\n\")\n\n# Validation predictions (for metrics)\np_va = predict_avg(models, X_va_s, id_va) if X_va_s is not None else None\n\n# Test predictions (for submission)\np_te = predict_avg(models, X_te_s, id_te) if X_te_s is not None else None\n\nprint(\"âœ… Predictions complete:\")\nif p_va is not None:\n    print(f\"   Validation: {p_va.shape} = {len(p_va):,} configs\")\n    print(f\"               Across {len(np.unique(id_va))} files\")\nif p_te is not None:\n    print(f\"   Test:       {p_te.shape} = {len(p_te):,} configs\")\n    print(f\"               Across {len(np.unique(id_te))} files\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T16:25:15.629709Z","iopub.execute_input":"2025-11-04T16:25:15.629958Z","iopub.status.idle":"2025-11-04T16:25:18.129220Z","shell.execute_reply.started":"2025-11-04T16:25:15.629937Z","shell.execute_reply":"2025-11-04T16:25:18.128422Z"}},"outputs":[{"name":"stdout","text":"\nðŸ”® Generating predictions...\n\nâœ… Predictions complete:\n   Validation: (1042735,) = 1,042,735 configs\n               Across 676 files\n   Test:       (1420536,) = 1,420,536 configs\n               Across 844 files\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"---\n\n## ðŸ“Š Section 7: Evaluation Metrics\n\n### Metrics Explained\n\n#### **Accuracy @ 1 (Acc@1)**\nPercentage of files where we correctly predict the best configuration.\n```\nFor each file:\n  true_best = argmin(true_runtimes)\n  pred_best = argmin(predicted_runtimes)\n  correct if true_best == pred_best\n```\n\n#### **Average Regret**\nHow much slower our predicted config is compared to the true best, on average.\n```\nregret = (runtime_of_predicted_best - runtime_of_true_best) / runtime_of_true_best\n```\n\nLower regret = better predictions!\n\n### Important Note\nMetrics are computed on **ORIGINAL runtime scale**, even though we trained on log(runtime).","metadata":{}},{"cell_type":"code","source":"# ===========================\n# 7.1 METRIC FUNCTIONS\n# ===========================\n\n\ndef acc1_and_regret(ids, cfg_idx, y_true, y_pred, use_log_target: bool):\n    \"\"\"\n    Compute Accuracy@1 and Average Regret.\n    \n    Args:\n        ids: [N] file identifiers\n        cfg_idx: [N] config indices\n        y_true: [N] true targets (possibly log-scaled)\n        y_pred: [N] predicted targets\n        use_log_target: Whether y_true is log-scaled\n    \n    Returns:\n        acc: Accuracy@1 (fraction of correct best configs)\n        regret: Average regret (on original runtime scale)\n    \"\"\"\n    df = pd.DataFrame({\"id\": ids, \"cfg\": cfg_idx, \"y\": y_true, \"p\": y_pred})\n\n    # Convert to original runtime scale if needed\n    if use_log_target:\n        y_orig = np.exp(df[\"y\"].values) - 1e-12\n    else:\n        y_orig = df[\"y\"].values\n    df[\"y_orig\"] = y_orig\n\n    # Find best configs per file\n    idx_true_min = df.groupby(\"id\")[\"y\"].idxmin()  # Based on true values\n    idx_pred_min = df.groupby(\"id\")[\"p\"].idxmin()  # Based on predictions\n\n    # Accuracy@1: Compare config indices\n    true_best_cfg = df.loc[idx_true_min, [\"id\", \"cfg\"]].set_index(\"id\")[\"cfg\"]\n    pred_best_cfg = df.loc[idx_pred_min, [\"id\", \"cfg\"]].set_index(\"id\")[\"cfg\"]\n    acc = (true_best_cfg == pred_best_cfg).mean()\n\n    # Regret: Compare original runtime values\n    best_true_val = df.loc[idx_true_min, [\"id\", \"y_orig\"]].set_index(\"id\")[\"y_orig\"]\n    pred_true_val = df.loc[idx_pred_min, [\"id\", \"y_orig\"]].set_index(\"id\")[\"y_orig\"]\n    regret = (\n        (pred_true_val - best_true_val) / np.clip(best_true_val, 1e-12, None)\n    ).mean()\n\n    return float(acc), float(regret)\n\n\nprint(\"\\nâœ… Metric functions defined\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T16:25:18.130128Z","iopub.execute_input":"2025-11-04T16:25:18.130638Z","iopub.status.idle":"2025-11-04T16:25:18.137915Z","shell.execute_reply.started":"2025-11-04T16:25:18.130615Z","shell.execute_reply":"2025-11-04T16:25:18.137273Z"}},"outputs":[{"name":"stdout","text":"\nâœ… Metric functions defined\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# ===========================\n# 7.2 COMPUTE METRICS\n# ===========================\n\nif p_va is not None:\n    print(\"\\nðŸ“Š Validation Metrics:\\n\" + \"=\" * 60)\n    \n    acc, reg = acc1_and_regret(\n        id_va, cfg_va, y_va, p_va, use_log_target=USE_LOG_TARGET\n    )\n    \n    print(f\"\\n  Accuracy @ 1:     {acc:.4f}  ({acc*100:.2f}%)\")\n    print(f\"  Average Regret:   {reg:.6f}\")\n    print(f\"\\n  Interpretation:\")\n    print(f\"    â€¢ We correctly pick the best config {acc*100:.1f}% of the time\")\n    print(f\"    â€¢ When wrong, predicted config is ~{reg*100:.2f}% slower on average\")\n    print(\"\\n\" + \"=\" * 60)\nelse:\n    print(\"\\nâš ï¸  No validation data available; skipping metrics.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T16:25:18.138962Z","iopub.execute_input":"2025-11-04T16:25:18.139186Z","iopub.status.idle":"2025-11-04T16:25:18.398202Z","shell.execute_reply.started":"2025-11-04T16:25:18.139164Z","shell.execute_reply":"2025-11-04T16:25:18.397542Z"}},"outputs":[{"name":"stdout","text":"\nðŸ“Š Validation Metrics:\n============================================================\n\n  Accuracy @ 1:     0.1065  (10.65%)\n  Average Regret:   0.190802\n\n  Interpretation:\n    â€¢ We correctly pick the best config 10.7% of the time\n    â€¢ When wrong, predicted config is ~19.08% slower on average\n\n============================================================\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"---\n\n## ðŸ“¤ Section 8: Submission Generation\n\n### Output Format\nThe competition requires a CSV with:\n- **ID**: Unique identifier (e.g., `tile:xla:abc123...`)\n- **TopConfigs**: Top 5 config indices separated by semicolons (e.g., `\"3;15;7;2;11\"`)\n\n### Two-Part Submission\n1. **Tile predictions** (this notebook): For `tile:xla:*` IDs\n2. **Layout predictions** (separate notebook): For `layout:*` IDs\n\nWe generate tile predictions, then append the layout rows from sample_submission.csv unchanged.","metadata":{}},{"cell_type":"code","source":"# ===========================\n# 8.1 GENERATE TILE SUBMISSION\n# ===========================\n\nprint(\"\\nðŸ“¤ Creating submission file...\\n\")\n\nassert p_te is not None and len(p_te) == len(id_te), \"Missing test predictions.\"\n\n# Create DataFrame\ndf_te = pd.DataFrame({\"ID\": id_te, \"cfg\": cfg_te, \"p\": p_te})\n\nprint(f\"  Test predictions: {len(df_te):,} configs\")\nprint(f\"  Unique files: {df_te['ID'].nunique()}\")\n\n# Sort by predicted runtime (ascending = faster configs first)\ndf_sorted = df_te.sort_values([\"ID\", \"p\"], ascending=[True, True])\n\n# Take top 5 configs per file\ntop5 = df_sorted.groupby(\"ID\", as_index=False).head(5)\n\nprint(f\"  Top-5 configs per file: {len(top5):,} rows\")\n\n# Aggregate into semicolon-separated strings\ntile_sub = (\n    top5.groupby(\"ID\")[\"cfg\"]\n    .apply(lambda s: \";\".join(s.astype(int).astype(str).tolist()))\n    .reset_index()\n)\n\n# Format IDs (add \"tile:xla:\" prefix if missing)\ntile_sub[\"ID\"] = tile_sub[\"ID\"].astype(str).map(lambda x: x if \":\" in x else f\"tile:xla:{x}\")\ntile_sub.columns = [\"ID\", \"TopConfigs\"]\n\nprint(f\"  Tile submission rows: {len(tile_sub)}\")\nprint(f\"\\n  Example entries:\")\ndisplay(tile_sub.head(3))\n\n# Save tile-only submission\ntile_path = WORK_DIR / \"submission_tile_top5.csv\"\ntile_sub.to_csv(tile_path, index=False)\nprint(f\"\\n  âœ… Saved: {tile_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T16:25:18.398955Z","iopub.execute_input":"2025-11-04T16:25:18.399197Z","iopub.status.idle":"2025-11-04T16:25:19.362436Z","shell.execute_reply.started":"2025-11-04T16:25:18.399179Z","shell.execute_reply":"2025-11-04T16:25:19.361721Z"}},"outputs":[{"name":"stdout","text":"\nðŸ“¤ Creating submission file...\n\n  Test predictions: 1,420,536 configs\n  Unique files: 844\n  Top-5 configs per file: 4,192 rows\n  Tile submission rows: 844\n\n  Example entries:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                                          ID               TopConfigs\n0  tile:xla:0023795810403f8b0b244d88c901322f  464;1511;1638;1850;2367\n1  tile:xla:005c91ca7a50fffc663678fd44316f04       117;79;229;252;188\n2  tile:xla:0070642211d5a98a16b94f4d7df229fe      254;577;189;805;813","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>TopConfigs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>tile:xla:0023795810403f8b0b244d88c901322f</td>\n      <td>464;1511;1638;1850;2367</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>tile:xla:005c91ca7a50fffc663678fd44316f04</td>\n      <td>117;79;229;252;188</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>tile:xla:0070642211d5a98a16b94f4d7df229fe</td>\n      <td>254;577;189;805;813</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\n  âœ… Saved: /kaggle/working/submission_tile_top5.csv\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# ===========================\n# 8.2 MERGE WITH LAYOUT ROWS\n# ===========================\n\nprint(\"\\nðŸ“‹ Adding layout predictions from sample submission...\\n\")\n\nassert SAMPLE_SUB is not None and Path(SAMPLE_SUB).exists(), \"sample_submission.csv not found.\"\n\n# Load sample submission\nsample_raw = pd.read_csv(SAMPLE_SUB)\nsample_cols = list(sample_raw.columns)\n\n# Standardize column names\nsample_df = sample_raw.rename(\n    columns={sample_cols[0]: \"ID\", sample_cols[1]: \"TopConfigs\"}\n)[[\"ID\", \"TopConfigs\"]]\n\n# Extract layout rows (these are handled by a separate notebook)\nlayout_rows = sample_df[sample_df[\"ID\"].str.startswith(\"layout:\", na=False)].copy()\n\nprint(f\"  Layout rows from sample: {len(layout_rows)}\")\n\n# Combine tile + layout\nfinal = pd.concat([tile_sub, layout_rows], ignore_index=True)\n\n# Restore original column names\nfinal = final.rename(columns={\"ID\": sample_cols[0], \"TopConfigs\": sample_cols[1]})\n\nprint(f\"  Final submission rows: {len(final)}\")\nprint(f\"    â€¢ Tile:   {len(tile_sub)}\")\nprint(f\"    â€¢ Layout: {len(layout_rows)}\")\n\n# Save final submission\nfinal_path = WORK_DIR / \"submission.csv\"\nfinal.to_csv(final_path, index=False)\n\nprint(f\"\\n  âœ… Saved: {final_path}\")\nprint(\"\\n  Preview:\")\ndisplay(final.head(5))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T16:25:19.364837Z","iopub.execute_input":"2025-11-04T16:25:19.365074Z","iopub.status.idle":"2025-11-04T16:25:19.400287Z","shell.execute_reply.started":"2025-11-04T16:25:19.365050Z","shell.execute_reply":"2025-11-04T16:25:19.399469Z"}},"outputs":[{"name":"stdout","text":"\nðŸ“‹ Adding layout predictions from sample submission...\n\n  Layout rows from sample: 50\n  Final submission rows: 894\n    â€¢ Tile:   844\n    â€¢ Layout: 50\n\n  âœ… Saved: /kaggle/working/submission.csv\n\n  Preview:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                                          ID               TopConfigs\n0  tile:xla:0023795810403f8b0b244d88c901322f  464;1511;1638;1850;2367\n1  tile:xla:005c91ca7a50fffc663678fd44316f04       117;79;229;252;188\n2  tile:xla:0070642211d5a98a16b94f4d7df229fe      254;577;189;805;813\n3  tile:xla:008191e0c67a6e7a62cde1a3e1d66795    1115;1051;349;635;444\n4  tile:xla:008730b43f100be7c2800d7cb89578a4      451;736;281;316;987","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>TopConfigs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>tile:xla:0023795810403f8b0b244d88c901322f</td>\n      <td>464;1511;1638;1850;2367</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>tile:xla:005c91ca7a50fffc663678fd44316f04</td>\n      <td>117;79;229;252;188</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>tile:xla:0070642211d5a98a16b94f4d7df229fe</td>\n      <td>254;577;189;805;813</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>tile:xla:008191e0c67a6e7a62cde1a3e1d66795</td>\n      <td>1115;1051;349;635;444</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>tile:xla:008730b43f100be7c2800d7cb89578a4</td>\n      <td>451;736;281;316;987</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}